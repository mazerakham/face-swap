V1 is complete.  We're now building V2.

The main improvements for V2 are the following:

1.  Target images with multiple faces.

Often the user will generate a target image which has multiple
faces, typically a most prominent face and then "background" faces.
It is important that we identify the most prominent face and
use it as the target of the face-swap in the last step.

In order to accomplish this: when performing the face swap,
we will look at all candidate faces in the target image, 
as identified by the "get bounding boxes" API call, and select
the face whose bounding box has the largest area - rather than
simply selecting the first one in the array.

2.  Headshot description for more relevant target images.

The initial target image and target image corrections will 
be improved if we include a description of the user’s headshot upload.  

2a. When the headshot is uploaded, use OpenAI API to obtain a 
 description of the headshot.  

2b.  Pass the description back to OpenAI GPT 4o with a prompt to 
clean up the description, removing any irrelevant details which 
are not describing actual characteristics of the person, such as descriptions of their pose or background. Call this the “final user description”.  

2c. Include the final user description in all target image generation 
requests.  
